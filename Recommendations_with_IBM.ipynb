{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations with IBM\n",
    "\n",
    "In this notebook, you will be putting your recommendation skills to use on real data from the IBM Watson Studio platform. \n",
    "\n",
    "\n",
    "You may either submit your notebook through the workspace here, or you may work from your local machine and submit through the next page.  Either way assure that your code passes the project [RUBRIC](https://review.udacity.com/#!/rubrics/2322/view).  **Please save regularly.**\n",
    "\n",
    "By following the table of contents, you will build out a number of different methods for making recommendations that can be used for different situations. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Extras & Concluding](#conclusions)\n",
    "\n",
    "At the end of the notebook, you will find directions for how to submit your work.  Let's get started by importing the necessary libraries and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Exploratory Data Analysis\n",
      "Number of Different Articles:  714\n",
      "Number of Different Users:  5148\n",
      "Average Article Interaction per User:  8.93\n",
      "Max Article Interaction per User:  364\n",
      "Min Article Interaction per User:  1\n",
      "Total Article Interaction of Users:  45993\n",
      "Percentage of Users Only Interacted Only Once:  27.51 %\n",
      "Percentage of Users Interacted Less than 50 Times:  97.36 %\n",
      "Percentage of Users Interacted Less than 100 Times:  99.49 %\n",
      "Percentage of Users Interacted More than 100 Times:  0.51 %\n"
     ]
    }
   ],
   "source": [
    "# Some summary points for user-artcile interaction\n",
    "# first lets find out interaction by pivotinf users a.k.a. emailS. \n",
    "interactions = df.groupby('email').count()\n",
    "\n",
    "print('Some Exploratory Data Analysis')\n",
    "print('Number of Different Articles: ', df['article_id'].nunique())\n",
    "print('Number of Different Users: ', df['email'].nunique())\n",
    "print('Average Article Interaction per User: ', round(interactions.mean()[0],2))\n",
    "print('Max Article Interaction per User: ', interactions.max()[0])\n",
    "print('Min Article Interaction per User: ', interactions.min()[0])\n",
    "print('Total Article Interaction of Users: ', df.count()['article_id'])\n",
    "print('Percentage of Users Only Interacted Only Once: ', round(100*interactions[interactions['article_id']==1].shape[0]/interactions.shape[0],2),'%')\n",
    "print('Percentage of Users Interacted Less than 50 Times: ', round(100*interactions[interactions['article_id']<=50].shape[0]/interactions.shape[0],2),'%')\n",
    "print('Percentage of Users Interacted Less than 100 Times: ', round(100*interactions[interactions['article_id']<=100].shape[0]/interactions.shape[0],2),'%')\n",
    "print('Percentage of Users Interacted More than 100 Times: ', round(100*interactions[interactions['article_id']>100].shape[0]/interactions.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Interaction Distributionof Users')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f53167668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of users interaction with artciles.\n",
    "# it seems most of the interactions happened less than 50 times\n",
    "# which supports the statistics we summarized above.\n",
    "df.groupby('email').count()['article_id'].plot(kind='hist', bins=25, figsize=(12,8), colormap='viridis')\n",
    "plt.title('Interaction Distributionof Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3 number of articles or fewer.\n",
      "The maximum number of user-article interactions by any 1 user is 364.\n"
     ]
    }
   ],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "median_val = interactions['article_id'].median()\n",
    "max_views_by_user = interactions['article_id'].max()\n",
    "\n",
    "print('50% of individuals interact with {} number of articles or fewer.'.format(int(median_val)))\n",
    "print('The maximum number of user-article interactions by any 1 user is {}.'.format(max_views_by_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Total Articles:  1056\n",
      "Number of Unique Articles:  1051\n",
      "Number of Duplicate Articles:  5\n"
     ]
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "print('Number of Total Articles: ', df_content['article_id'].shape[0])\n",
    "print('Number of Unique Articles: ', df_content['article_id'].nunique())\n",
    "print('Number of Duplicate Articles: ', df_content['article_id'].shape[0]-df_content['doc_full_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content = df_content.drop_duplicates(subset='article_id')\n",
    "# 5 Rows Dropped\n",
    "df_content.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Articles:  714\n",
      "Total Articles:  1051\n",
      "Unique Users:  5148\n",
      "Total Article Interaction:  45993\n"
     ]
    }
   ],
   "source": [
    "unique_articles = df['article_id'].nunique() # The number of unique articles that have at least one interaction\n",
    "total_articles = df_content.shape[0] # The number of unique articles on the IBM platform\n",
    "unique_users =  df['email'].nunique() # The number of unique users\n",
    "user_article_interactions = df.count()['article_id'] # The number of user-article interactions\n",
    "\n",
    "print('Unique Articles: ', unique_articles)\n",
    "print('Total Articles: ', total_articles)\n",
    "print('Unique Users: ', unique_users)\n",
    "print('Total Article Interaction: ', user_article_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Viewed Article ID:  1429.0\n",
      "Most Viewed Article Max View Count:  937\n"
     ]
    }
   ],
   "source": [
    "# First lets create al viwe numbers df for analysis.\n",
    "view_numbers = df.groupby('article_id')['email'].count().sort_values(ascending=False)\n",
    "\n",
    "most_viewed_article_id = str(view_numbers.index[0]) # The most viewed article in the dataset as a string with one value following the decimal \n",
    "max_views = view_numbers.iloc[0] # The most viewed article in the dataset was viewed how many times?\n",
    "\n",
    "print('Most Viewed Article ID: ', most_viewed_article_id)\n",
    "print('Most Viewed Article Max View Count: ', max_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    # Fist create a view number df, sort, make a list of ids as string from it.\n",
    "    # Than find df rows according to list of ids, find values from tittle column.\n",
    "    # Finally return unique title names.\n",
    "    top_articles = df[df['article_id'].isin([str(item) for item in df.groupby('article_id')['user_id'].count().sort_values(ascending=False).iloc[:n].index.tolist()])]['title'].unique()\n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    # Fist create a view number df, sort, take n first indexes, make a list of ids as string from it.\n",
    "    # Than return as top n artictle ids list.\n",
    "    top_article_ids = [str(item) for item in df.groupby('article_id')['user_id'].count().sort_values(ascending=False).iloc[:n].index.tolist()]\n",
    "    \n",
    "    return top_article_ids # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['healthcare python streaming application demo'\n",
      " 'use deep learning for image classification'\n",
      " 'apache spark lab, part 1: basic concepts'\n",
      " 'predicting churn with the spss random tree algorithm'\n",
      " 'analyze energy consumption in buildings' 'visualize car data with brunel'\n",
      " 'use xgboost, scikit-learn & ibm watson machine learning apis'\n",
      " 'gosales transactions for logistic regression model'\n",
      " 'insights from new york car accident reports'\n",
      " 'finding optimal locations of new store using decision optimization']\n",
      "['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    # Fist create a groupped table indexes as first layer, and article id as second layer.\n",
    "    # Chagence counted column values (title in our case) to 1's as instructed.\n",
    "    # Than unstacked grouped data indexes as user_id, and columns as article id and user fill values as 0 as isntructed.\n",
    "    # Return user_item.\n",
    "    user_item = df.groupby(['user_id', 'article_id']).count()\n",
    "    user_item['title'] = 1\n",
    "    user_item = user_item.unstack(fill_value=0)\n",
    "    user_item = user_item.title\n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    # Create a dict, calculate similarities as dot products in for loop,\n",
    "    # Assign similarity values with their relative indexes to empty dict.\n",
    "    d_similarity = {}\n",
    "    for user in user_item.index.values:\n",
    "        d_similarity[user] = np.dot(user_item.loc[user_id].values, user_item.loc[user].values)\n",
    "    d_similarity = {'user_id':list(d_similarity.keys()), 'similarity':list(d_similarity.values())}\n",
    "\n",
    "    # sort by similarity\n",
    "    # Create a df to sort simply.\n",
    "    df_similarity = pd.DataFrame.from_dict(d_similarity).set_index('user_id').sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # remove the own user's id\n",
    "    df_similarity = df_similarity.drop(user_id, axis=0)\n",
    "\n",
    "    # create list of just the ids\n",
    "    most_similar_users = df_similarity.index.tolist()\n",
    "       \n",
    "    return most_similar_users # return a list of the users in order from most to least similar        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 5041]\n",
      "The 5 most similar users to user 3933 are: [1, 23, 3782, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Your code here\n",
    "    # From given ids list find indexes in list, take title names from title column,\n",
    "    # Return unique title names as a list.\n",
    "    article_names = list(df[df['article_id'].isin(article_ids)]['title'].unique())\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # Your code here\n",
    "    # First find user id from user_item matrix using np.where as we learned from lesson and store article ids into a list.\n",
    "    # Second call article names function with ids list.\n",
    "    article_ids = [str(item) for item in user_item.loc[user_id].iloc[np.where(user_item.loc[user_id] == 1)].index.tolist()]\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    # My code here follows logic i've learned in lesson.\n",
    "    # Define an empty recs list. \n",
    "    # Call find similar users function and use close user ids in a for loop.\n",
    "    # Find close users read article names from get_user_articles function.\n",
    "    # Append it to recs list untlis list lenght equeals given lenght of m.\n",
    "    # Return recs as recomended article ids.\n",
    "    recs = []  \n",
    "    for close in find_similar_users(user_id):\n",
    "        if len(recs) != m:\n",
    "            article_ids, _ = get_user_articles(close)\n",
    "            recs.append(np.setdiff1d(article_ids, recs)[0])\n",
    "            \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['access db2 warehouse on cloud and db2 with python',\n",
       " 'analyze energy consumption in buildings',\n",
       " 'access mysql with python',\n",
       " 'access mysql with r',\n",
       " 'analyze accident reports on amazon emr spark',\n",
       " 'tensorflow quick tips',\n",
       " '1448    i ranked every intro to data science course on...\\nName: title, dtype: object',\n",
       " 'the pandas data analysis library',\n",
       " 'data tidying in data science experience',\n",
       " 'recommender systems: approaches & algorithms']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Results\n",
    "get_article_names(user_user_recs(1, 10)) # Return 10 recommendations for user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # Your code here\n",
    "    # compute similarity of each user to the provided user\n",
    "    # Create a dict, calculate similarities as dot products in for loop,\n",
    "    # Assign similarity values with their relative indexes to empty dict.\n",
    "    d_similarity = {}\n",
    "    for user in user_item.index.values:\n",
    "        d_similarity[user] = np.dot(user_item.loc[user_id].values, user_item.loc[user].values)\n",
    "    d_similarity = {'user_id':list(d_similarity.keys()), 'similarity':list(d_similarity.values())}\n",
    "\n",
    "    # create a dataframe from similarities\n",
    "    df_similarity = pd.DataFrame.from_dict(d_similarity)\n",
    "    \n",
    "    # add num_interactions from a groupped df with pandas merge.\n",
    "    df_similarity = df_similarity.drop(user_id, axis=0).merge(df.groupby('user_id').count()['article_id'].reset_index(), on='user_id')   \n",
    "    \n",
    "    # remove the own user's id\n",
    "    user_id_index = df_similarity[df_similarity['user_id']==user_id].index[0]\n",
    "    df_similarity = df_similarity.drop(user_id_index, axis=0)\n",
    "    \n",
    "    # sort neighbors_df ands assign column names.\n",
    "    neighbors_df = df_similarity.sort_values(by=['similarity', 'article_id'], ascending=False)\n",
    "    neighbors_df.columns = ['user_id', 'similarity', 'num_interactions']\n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # Your code here\n",
    "    # My code here follows logic i've learned in lesson.\n",
    "    # Call get_top_sorted_users find neigbours of our user id.\n",
    "    # Define an empty recs list. \n",
    "    # Use close user ids in a for loop.\n",
    "    # Find close users read article names from get_user_articles function.\n",
    "    # Append it to recs list untlis list lenght equeals given lenght of m.\n",
    "    # Find reccomended article names from get_article_names function.\n",
    "    # Return recs and rec_names as recomended article ids and names.\n",
    "    df_neighbors = get_top_sorted_users(user_id)\n",
    "    recs = []\n",
    "    rec_names = []\n",
    "    for close in df_neighbors['user_id']:\n",
    "        if len(recs) != m:\n",
    "            article_ids, _ = get_user_articles(close)\n",
    "            recs.append(np.setdiff1d(article_ids, recs)[0])\n",
    "    \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommendations for user 20 are the following article ids:\n",
      "['1024.0', '1085.0', '1014.0', '1059.0', '1006.0', '1035.0', '1052.0', '1161.0', '1053.0', '110.0']\n",
      "\n",
      "The top 10 recommendations for user 20 are the following article names:\n",
      "['access db2 warehouse on cloud and db2 with python', 'access mysql with python', 'airbnb data for analytics: amsterdam calendar', '1448    i ranked every intro to data science course on...\\nName: title, dtype: object', 'pixiedust: magic for your python notebook', 'using deep learning to reconstruct high-resolution audio', 'machine learning for the enterprise.', 'essentials of machine learning algorithms (with python and r codes)', 'airbnb data for analytics: chicago listings', 'analyze data, build a dashboard with spark and pixiedust']\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "user1_most_sim = get_top_sorted_users(1)['user_id'].values[0]# Find the user that is most similar to user 1 \n",
    "user131_10th_sim = get_top_sorted_users(131)['user_id'].values[9]# Find the 10th most similar user to user 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.** \n",
    "\n",
    "**Answer BK:**\n",
    "\n",
    "*Part II, Rank Based Recomendation are the most capable ones for new users. Because they are immune to cold start for new users since they are recommending according to item ranks and don't consider any history on neither items nor users.*\n",
    "\n",
    "*Since new users have empty user-item-matrices, we can't calculate any similar users for them. Therefore every function we created at Part III User Based Collaborative Filtering can't provide an answer for us.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "new_user_recs = get_top_article_ids(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_content_recs():\n",
    "    '''\n",
    "    INPUT:\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write an explanation of your content based recommendation system here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n",
    "### This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "\n",
    "# make a recommendations for a user who only has interacted with article id '1427.0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1              0.0  ...      0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...      1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "u, s, vt = np.linalg.svd(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.** \n",
    "\n",
    "**Answer BK:** \n",
    "\n",
    "*SVD can't handle missing values. Since no nan values on our matrix, svd works this time without errors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f50fc8a58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    # Call create_user_item_matrix for df_train and df_test\n",
    "    user_item_train = create_user_item_matrix(df_train)\n",
    "    user_item_test = create_user_item_matrix(df_test)\n",
    "    \n",
    "    # Find item matrix index and columns as test_idx and test_arts\n",
    "    test_idx = user_item_test.index.tolist()\n",
    "    test_arts = user_item_test.columns.tolist()\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train df:  (4487, 714)\n",
      "Shape of the test df:  (682, 574)\n",
      "Different Users in Test:  662\n",
      "Different Articles in Test:  0\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the train df: ', user_item_train.shape)\n",
    "print('Shape of the test df: ', user_item_test.shape)\n",
    "print('Different Users in Test: ', len(set(test_idx) - set(user_item_train.index.tolist()))) # Users not in train data.\n",
    "print('Different Articles in Test: ', len(set(test_arts) - set(user_item_train.columns.tolist()))) # Articles not in train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test movies are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a, \n",
    "    'How many articles can we make predictions for in the test set?': b,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?': d\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)\n",
    "\n",
    "# IMPORTANT NOTE: There were movies at test.py's wording instead of articles. \n",
    "# I'd to chage that to articles for dictionary keys to match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of u, s, vt: (4487, 4487) (714,) (714, 714)\n"
     ]
    }
   ],
   "source": [
    "# lets create and explore u, s and vt\n",
    "# we have 4817 users, 714 latent fatures (min(user_id, article_id)) and 714 articles from train data.\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train, full_matrices=True)\n",
    "print('Shapes of u, s, vt:', u_train.shape, s_train.shape, vt_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5005211634 0.090633668675 1\n",
      "21.9148667399 0.107045006299 2\n",
      "20.1532632237 0.120923970848 3\n",
      "19.4490314963 0.13384991488 4\n",
      "18.8449800784 0.145985414953 5\n",
      "18.3778261904 0.157526711273 6\n",
      "17.9970100916 0.168594657289 7\n",
      "17.5847739074 0.179161369748 8\n",
      "17.409210313 0.189518142701 9\n",
      "16.950933523 0.199336832809 10\n",
      "16.4733189617 0.208610009326 11\n",
      "16.4036423886 0.217804906935 12\n",
      "16.3003888734 0.226884413408 13\n",
      "16.0805291777 0.235720642858 14\n",
      "15.8101396367 0.244262213229 15\n",
      "15.3614063133 0.252325800022 16\n",
      "15.2037645522 0.260224735799 17\n",
      "15.1684509567 0.268087020668 18\n",
      "14.9907763284 0.275766195591 19\n",
      "14.7498901021 0.283200560613 20\n",
      "14.6933704532 0.290578059768 21\n",
      "14.6183591398 0.297880425267 22\n",
      "14.3838016897 0.304950332014 23\n",
      "14.283161654 0.311921651958 24\n",
      "14.1251721938 0.318739601982 25\n",
      "14.0936410808 0.325527147051 26\n",
      "14.0211522865 0.332245049985 27\n",
      "13.8665646951 0.338815635566 28\n",
      "13.8011137959 0.345324340527 29\n",
      "13.6423895069 0.351684195348 30\n",
      "13.5980368406 0.35800276444 31\n",
      "13.5221422087 0.364250998786 32\n",
      "13.2639650478 0.370262916801 33\n",
      "13.2171928835 0.376232510422 34\n",
      "13.1550641425 0.382146114598 35\n",
      "13.0129233486 0.387932615899 36\n",
      "12.8617259675 0.39358543147 37\n",
      "12.8030708912 0.399186806 38\n",
      "12.7119136682 0.404708701472 39\n",
      "12.6393232053 0.410167712239 40\n",
      "12.5729593686 0.415569547507 41\n",
      "12.4947413605 0.420904380806 42\n",
      "12.4607503187 0.426210227529 43\n",
      "12.3602485323 0.43143083113 44\n",
      "12.2796887687 0.436583604376 45\n",
      "12.2575243318 0.441717793234 46\n",
      "12.1444467345 0.446757691624 47\n",
      "12.1098223805 0.451768893035 48\n",
      "12.0659894875 0.456743882862 49\n",
      "11.9683226957 0.461638659658 50\n",
      "11.8740566796 0.466456634714 51\n",
      "11.7596701639 0.471182230749 52\n",
      "11.6350143478 0.475808172482 53\n",
      "11.5057507443 0.480331897884 54\n",
      "11.4835064556 0.484838148586 55\n",
      "11.4370522111 0.489308014745 56\n",
      "11.400109242 0.493749051197 57\n",
      "11.2996779921 0.498112184149 58\n",
      "11.2272622354 0.502419572657 59\n",
      "11.1420892142 0.506661855054 60\n",
      "11.0962267238 0.5108692856 61\n",
      "11.0484225512 0.515040541781 62\n",
      "10.971420019 0.519153857023 63\n",
      "10.8974650047 0.52321190594 64\n",
      "10.8416770013 0.527228512016 65\n",
      "10.777104484 0.531197415141 66\n",
      "10.676501976 0.53509256599 67\n",
      "10.6709951149 0.538983699695 68\n",
      "10.5781921114 0.542807447247 69\n",
      "10.4988713586 0.546574064927 70\n",
      "10.4700757325 0.550320049271 71\n",
      "10.4108337822 0.554023762367 72\n",
      "10.3506499362 0.557684777748 73\n",
      "10.2976687139 0.56130841023 74\n",
      "10.2728090559 0.564914568168 75\n",
      "10.2067681122 0.568474509232 76\n",
      "10.1440703959 0.571990848905 77\n",
      "10.036292561 0.57543286532 78\n",
      "10.0071708703 0.578854935742 79\n",
      "9.93817790773 0.582229982903 80\n",
      "9.89300365154 0.585574417063 81\n",
      "9.87890505755 0.588909325658 82\n",
      "9.79913652712 0.592190595364 83\n",
      "9.78093689326 0.595459687987 84\n",
      "9.73608625779 0.5986988684 85\n",
      "9.68518702397 0.601904269155 86\n",
      "9.6162446638 0.605064198127 87\n",
      "9.58669707651 0.608204738068 88\n",
      "9.50660150274 0.611293019647 89\n",
      "9.47327147687 0.614359684234 90\n",
      "9.42780299329 0.617396981572 91\n",
      "9.41662189902 0.620427078892 92\n",
      "9.36810992976 0.623426036097 93\n",
      "9.2724943289 0.626364088007 94\n",
      "9.25467144279 0.62929085617 95\n",
      "9.21764937573 0.632194254885 96\n",
      "9.19806283921 0.635085327876 97\n",
      "9.17123435364 0.637959560365 98\n",
      "9.11287703812 0.640797331275 99\n",
      "9.05256881106 0.643597666229 100\n",
      "9.04299499144 0.646392081155 101\n",
      "8.98722050596 0.649152132154 102\n",
      "8.96207393325 0.651896759313 103\n",
      "8.92912979384 0.654621245333 104\n",
      "8.85516863803 0.657300783728 105\n",
      "8.83533520218 0.65996833253 106\n",
      "8.80450696978 0.662617298597 107\n",
      "8.72367273229 0.665217847597 108\n",
      "8.6645070101 0.667783241314 109\n",
      "8.65302806733 0.670341842145 110\n",
      "8.61160414501 0.672876004459 111\n",
      "8.5740713075 0.675388125112 112\n",
      "8.52162014593 0.677869604401 113\n",
      "8.4749874227 0.680323999283 114\n",
      "8.46934508298 0.682775127158 115\n",
      "8.39594344796 0.685183952553 116\n",
      "8.37307857322 0.68757967579 117\n",
      "8.34580123822 0.689959815152 118\n",
      "8.27134328721 0.692297674631 119\n",
      "8.21908800344 0.694606087958 120\n",
      "8.20089443141 0.696904292902 121\n",
      "8.18865551349 0.699195643336 122\n",
      "8.15053957623 0.701465712206 123\n",
      "8.09645970722 0.703705756622 124\n",
      "8.06448506977 0.705928143152 125\n",
      "8.00969333858 0.70812043359 126\n",
      "7.98141764171 0.710297272969 127\n",
      "7.96248617168 0.712463797915 128\n",
      "7.94713449997 0.714621976796 129\n",
      "7.89620631004 0.716752583483 130\n",
      "7.87060584205 0.71886939719 131\n",
      "7.83965063136 0.720969592721 132\n",
      "7.80057095114 0.723048902015 133\n",
      "7.78675887465 0.725120854371 134\n",
      "7.74795744206 0.727172209091 135\n",
      "7.69761986321 0.729196995572 136\n",
      "7.67931813558 0.731212165303 137\n",
      "7.63847784176 0.733205957804 138\n",
      "7.61290832533 0.735186424356 139\n",
      "7.56256867621 0.737140786199 140\n",
      "7.53348018735 0.739080142532 141\n",
      "7.50187624947 0.741003261288 142\n",
      "7.48725798151 0.74291889251 143\n",
      "7.47237830543 0.744826917303 144\n",
      "7.45789824005 0.746727554473 145\n",
      "7.42513607201 0.748611529517 146\n",
      "7.41456797417 0.750490145504 147\n",
      "7.3510054869 0.752336690121 148\n",
      "7.34214615902 0.754178786561 149\n",
      "7.3151586439 0.756007365907 150\n",
      "7.28248038533 0.757819644494 151\n",
      "7.23686016455 0.759609288597 152\n",
      "7.2143866111 0.761387834735 153\n",
      "7.18655430056 0.763152684472 154\n",
      "7.17212590568 0.764910454771 155\n",
      "7.14274977706 0.766653855344 156\n",
      "7.11007171314 0.7683813403 157\n",
      "7.07786918784 0.770093212643 158\n",
      "7.05284185053 0.771793000033 159\n",
      "7.04632794851 0.773489649075 160\n",
      "6.9994083598 0.775163778291 161\n",
      "6.98201556007 0.776829597772 162\n",
      "6.94385325418 0.778477256944 163\n",
      "6.90676736597 0.780107363404 164\n",
      "6.87560762135 0.781722794656 165\n",
      "6.84768208026 0.783325130286 166\n",
      "6.82725051445 0.784917918339 167\n",
      "6.81735357979 0.786506091857 168\n",
      "6.77507986495 0.788074630238 169\n",
      "6.7619001039 0.789637071907 170\n",
      "6.72055257796 0.791180464026 171\n",
      "6.69494390249 0.792712116358 172\n",
      "6.67595359463 0.794235091905 173\n",
      "6.65523431977 0.795748628805 174\n",
      "6.61715369393 0.797244894627 175\n",
      "6.61238627976 0.798739005217 176\n",
      "6.58583982745 0.80022114321 177\n",
      "6.5698423152 0.801696089494 178\n",
      "6.52465892625 0.80315081797 179\n",
      "6.5115082752 0.804599688255 180\n",
      "6.48895501172 0.806038539305 181\n",
      "6.46204894755 0.807465482874 182\n",
      "6.42986617802 0.808878248698 183\n",
      "6.41851273845 0.810286029786 184\n",
      "6.40883772647 0.811689570006 185\n",
      "6.37142631424 0.8130767718 186\n",
      "6.34126624329 0.814450871635 187\n",
      "6.31313641475 0.815812807508 188\n",
      "6.29853857437 0.817168452265 189\n",
      "6.27359381343 0.818513380482 190\n",
      "6.22529602502 0.819837680324 191\n",
      "6.20726258923 0.821154318817 192\n",
      "6.19574535313 0.822466075941 193\n",
      "6.16644186536 0.823765454197 194\n",
      "6.14646207664 0.825056425905 195\n",
      "6.11648890563 0.826334837487 196\n",
      "6.10734914836 0.827609431309 197\n",
      "6.10144337021 0.828881561271 198\n",
      "6.07349636863 0.830142064215 199\n",
      "6.03653131069 0.831387270279 200\n",
      "6.01612584603 0.832624072158 201\n",
      "6.00066986134 0.833854527283 202\n",
      "5.9858448644 0.8350789101 203\n",
      "5.95839419553 0.836292088797 204\n",
      "5.95379250058 0.837503394331 205\n",
      "5.92048160519 0.838701183506 206\n",
      "5.89029023015 0.839886787627 207\n",
      "5.86311520608 0.841061477346 208\n",
      "5.85102279303 0.842231326571 209\n",
      "5.83594626548 0.843395154783 210\n",
      "5.81996126143 0.844552616138 211\n",
      "5.77735773007 0.84569319372 212\n",
      "5.77004223063 0.846830884648 213\n",
      "5.73771522759 0.847955863326 214\n",
      "5.72210328481 0.849074728348 215\n",
      "5.70845162793 0.850188261016 216\n",
      "5.69118286612 0.85129506673 217\n",
      "5.68365638102 0.852398946919 218\n",
      "5.65433747611 0.853491467842 219\n",
      "5.63928111099 0.854578178185 220\n",
      "5.59909790983 0.8556494568 221\n",
      "5.58214092942 0.856714256464 222\n",
      "5.56440463487 0.857772300441 223\n",
      "5.55391504178 0.858826359089 224\n",
      "5.52875711345 0.85987089009 225\n",
      "5.51225277531 0.860909194172 226\n",
      "5.48584100831 0.861937572096 227\n",
      "5.45945314926 0.862956080458 228\n",
      "5.45813703122 0.863974097812 229\n",
      "5.43960972826 0.864985215704 230\n",
      "5.40764504662 0.865984485283 231\n",
      "5.40303856712 0.86698205314 232\n",
      "5.36000308661 0.867963792925 233\n",
      "5.34852448429 0.868941332365 234\n",
      "5.33628523174 0.869914403034 235\n",
      "5.32051905771 0.87088173228 236\n",
      "5.2904005495 0.871838140767 237\n",
      "5.27484311996 0.872788932523 238\n",
      "5.25997986878 0.873734373619 239\n",
      "5.2482307081 0.874675595788 240\n",
      "5.24110218167 0.875614262822 241\n",
      "5.19154285491 0.876535261907 242\n",
      "5.18496455638 0.877453928441 243\n",
      "5.16990221468 0.878367265268 244\n",
      "5.14814712965 0.879272931577 245\n",
      "5.13536011148 0.880174104467 246\n",
      "5.11961478078 0.881069759727 247\n",
      "5.0887556096 0.88195465016 248\n",
      "5.08377201572 0.882837808235 249\n",
      "5.06424314589 0.883714194192 250\n",
      "5.0500719027 0.88458568224 251\n",
      "5.02786928105 0.885449524145 252\n",
      "5.01078666399 0.886307506068 253\n",
      "4.99052509201 0.887158563363 254\n",
      "4.96612207863 0.888001317891 255\n",
      "4.95971709424 0.888841899959 256\n",
      "4.9411012199 0.889676183764 257\n",
      "4.92979235778 0.890506653033 258\n",
      "4.9216611945 0.891334385022 259\n",
      "4.90245571047 0.892155669603 260\n",
      "4.87682197859 0.89296838805 261\n",
      "4.86607685772 0.89377752911 262\n",
      "4.83359967533 0.894575905471 263\n",
      "4.82246031901 0.895370606247 264\n",
      "4.81334449225 0.896162305441 265\n",
      "4.79264576601 0.896947210219 266\n",
      "4.77605659847 0.897726690695 267\n",
      "4.75661989468 0.898499839711 268\n",
      "4.73911669177 0.899267309197 269\n",
      "4.73536303431 0.900033563402 270\n",
      "4.71338475846 0.900792721271 271\n",
      "4.70728749827 0.901549916309 272\n",
      "4.66680008686 0.902294142083 273\n",
      "4.66550225879 0.903037953979 274\n",
      "4.64504027639 0.903775255755 275\n",
      "4.63543924864 0.904509512761 276\n",
      "4.62718854525 0.905241158259 277\n",
      "4.6156035669 0.905969144736 278\n",
      "4.60072284177 0.906692444718 279\n",
      "4.58903455976 0.907412074235 280\n",
      "4.54708580269 0.908118607495 281\n",
      "4.54324867028 0.908823948818 282\n",
      "4.53226870062 0.909525884971 283\n",
      "4.51306767572 0.910221886195 284\n",
      "4.50661759659 0.910915899391 285\n",
      "4.47304140315 0.911599609731 286\n",
      "4.46301445481 0.912280258242 287\n",
      "4.44647257982 0.912955870544 288\n",
      "4.4402778217 0.913629601652 289\n",
      "4.4256385453 0.914298897597 290\n",
      "4.41085324324 0.914963729005 291\n",
      "4.40331118901 0.915626288786 292\n",
      "4.39393231879 0.916286029123 293\n",
      "4.37630103021 0.916940485476 294\n",
      "4.36728015755 0.917592246547 295\n",
      "4.34742050636 0.918238093494 296\n",
      "4.32884476498 0.918878433058 297\n",
      "4.3159308095 0.919514957755 298\n",
      "4.30057256851 0.920146960367 299\n",
      "4.2910839987 0.920776177216 300\n",
      "4.2731049402 0.921400132445 301\n",
      "4.25778846717 0.922019622694 302\n",
      "4.244272912 0.922635186272 303\n",
      "4.22840357798 0.923246155272 304\n",
      "4.21425177386 0.923853041481 305\n",
      "4.18538901069 0.924451643216 306\n",
      "4.16957906456 0.925045731159 307\n",
      "4.16107358372 0.925637397827 308\n",
      "4.1583029148 0.92622827683 309\n",
      "4.14494719343 0.926815366333 310\n",
      "4.13269628257 0.927398990532 311\n",
      "4.12447695699 0.927980295555 312\n",
      "4.11771219565 0.928559695286 313\n",
      "4.0929852041 0.929132157283 314\n",
      "4.07016043417 0.929698252347 315\n",
      "4.06379236287 0.9302625774 316\n",
      "4.04273350919 0.930821068865 317\n",
      "4.03209567621 0.931376625028 318\n",
      "4.01946314112 0.931928705534 319\n",
      "4.01161625921 0.932478632578 320\n",
      "3.99528511797 0.933024091271 321\n",
      "3.98128269027 0.933565733283 322\n",
      "3.96301327668 0.9341024157 323\n",
      "3.94258635887 0.934633579833 324\n",
      "3.93176486176 0.93516183212 325\n",
      "3.92588072759 0.935688504464 326\n",
      "3.9096958993 0.936210843243 327\n",
      "3.90667567001 0.936732375323 328\n",
      "3.89095873068 0.937249719495 329\n",
      "3.87551804455 0.937762965808 330\n",
      "3.86161863025 0.938272537242 331\n",
      "3.85340058613 0.938779942111 332\n",
      "3.84950399008 0.939286321313 333\n",
      "3.8380611173 0.939789694507 334\n",
      "3.81101207862 0.940285997578 335\n",
      "3.81065246447 0.940782206989 336\n",
      "3.79543113709 0.941274460184 337\n",
      "3.77267267403 0.941760827704 338\n",
      "3.76456837344 0.942245107879 339\n",
      "3.76091667428 0.942728448989 340\n",
      "3.74162931746 0.94320684531 341\n",
      "3.72722527178 0.943681565384 342\n",
      "3.71476278665 0.944153116182 343\n",
      "3.68752964878 0.944617778392 344\n",
      "3.67092820712 0.945078266155 345\n",
      "3.66699208891 0.94553776694 346\n",
      "3.65113998005 0.945993303543 347\n",
      "3.63994667492 0.946446051349 348\n",
      "3.63516800744 0.946897611165 349\n",
      "3.62997921011 0.947347882798 350\n",
      "3.62272612921 0.947796356848 351\n",
      "3.59675681724 0.948238424221 352\n",
      "3.58557234722 0.948677746565 353\n",
      "3.56418215528 0.949111842875 354\n",
      "3.55375414387 0.949543402762 355\n",
      "3.53965209589 0.949971544402 356\n",
      "3.53441576941 0.95039842025 357\n",
      "3.52470604852 0.9508229539 358\n",
      "3.51483479426 0.951245112991 359\n",
      "3.50096881444 0.951663947827 360\n",
      "3.48796325874 0.95207967663 361\n",
      "3.47622123083 0.95249261109 362\n",
      "3.47007176474 0.952904085873 363\n",
      "3.46168935525 0.953313575116 364\n",
      "3.45036449232 0.953720389466 365\n",
      "3.42744763658 0.95412181775 366\n",
      "3.41677547543 0.954520750043 367\n",
      "3.41320702096 0.954918849489 368\n",
      "3.41058700211 0.955316337997 369\n",
      "3.3956300919 0.955710347829 370\n",
      "3.38043072663 0.956100838257 371\n",
      "3.36313531896 0.95648734315 372\n",
      "3.34864447369 0.956870524526 373\n",
      "3.34504414335 0.957252882383 374\n",
      "3.33822916649 0.957633683845 375\n",
      "3.32291357408 0.958010999134 376\n",
      "3.30871743355 0.958385097379 377\n",
      "3.29101092274 0.958755202385 378\n",
      "3.28322040483 0.959123557232 379\n",
      "3.27340968039 0.959489713975 380\n",
      "3.26499812421 0.959853991338 381\n",
      "3.26352788871 0.960217940705 382\n",
      "3.24391780027 0.96057752937 383\n",
      "3.23450945464 0.960935035228 384\n",
      "3.2220249967 0.961289786631 385\n",
      "3.22100765588 0.961644314048 386\n",
      "3.19849148589 0.961993902204 387\n",
      "3.19648415167 0.962343051702 388\n",
      "3.18807715556 0.962690367037 389\n",
      "3.17589819476 0.963035033841 390\n",
      "3.15529804714 0.963375243852 391\n",
      "3.14661689378 0.963713584402 392\n",
      "3.13233421805 0.964048860429 393\n",
      "3.11924243221 0.964381339699 394\n",
      "3.11460781771 0.964712831698 395\n",
      "3.09366515876 0.965039880773 396\n",
      "3.08017939284 0.965364084747 397\n",
      "3.07969245787 0.965688186224 398\n",
      "3.06151494232 0.966008473052 399\n",
      "3.04983127119 0.966326319921 400\n",
      "3.03504039795 0.96664109132 401\n",
      "3.03200729203 0.966955233892 402\n",
      "3.02680360368 0.967268299094 403\n",
      "3.02355617124 0.967580692885 404\n",
      "2.99942239014 0.967888119576 405\n",
      "2.98959246979 0.968193534527 406\n",
      "2.9788178765 0.968496751994 407\n",
      "2.96189963096 0.968796534984 408\n",
      "2.9542277277 0.969094766991 409\n",
      "2.94740810729 0.969391623694 410\n",
      "2.9395178464 0.969686893144 411\n",
      "2.93225181418 0.969980704677 412\n",
      "2.92676166438 0.970273417014 413\n",
      "2.90777985995 0.970562344834 414\n",
      "2.90637535219 0.970850993606 415\n",
      "2.90205902189 0.971138785657 416\n",
      "2.88374511599 0.971422956853 417\n",
      "2.86404209261 0.971703258149 418\n",
      "2.85416337967 0.971981629137 419\n",
      "2.85025442356 0.972259238154 420\n",
      "2.83962671059 0.972534780796 421\n",
      "2.83239773953 0.972808922299 422\n",
      "2.8145192008 0.973079613877 423\n",
      "2.80800446402 0.973349053771 424\n",
      "2.80072460813 0.973617098411 425\n",
      "2.79818892618 0.973884657913 426\n",
      "2.79450246851 0.97415151289 427\n",
      "2.77134686866 0.974413963801 428\n",
      "2.76592725161 0.974675389223 429\n",
      "2.74578146185 0.9749330203 430\n",
      "2.74241031003 0.975190019149 431\n",
      "2.72374529357 0.975443531602 432\n",
      "2.71424607496 0.97569527886 433\n",
      "2.70321711532 0.975944984395 434\n",
      "2.69472344836 0.976193123216 435\n",
      "2.68871940197 0.976440157525 436\n",
      "2.67693990127 0.97668503202 437\n",
      "2.66697729486 0.976928087238 438\n",
      "2.65222397586 0.977168460804 439\n",
      "2.64826622843 0.977408117515 440\n",
      "2.63549980355 0.977645469184 441\n",
      "2.62852771868 0.977881566708 442\n",
      "2.61881098694 0.978115921922 443\n",
      "2.59713160447 0.978346413057 444\n",
      "2.59420417562 0.978576384876 445\n",
      "2.58122867379 0.978804061936 446\n",
      "2.574196128 0.979030500075 447\n",
      "2.56731122881 0.979255728579 448\n",
      "2.56009319312 0.979479692396 449\n",
      "2.54838101206 0.979701611676 450\n",
      "2.53164705751 0.979920626056 451\n",
      "2.51140141718 0.980136151516 452\n",
      "2.50453033304 0.980350499254 453\n",
      "2.48417110198 0.980561376306 454\n",
      "2.47319927083 0.980770394712 455\n",
      "2.46267286002 0.98097763766 456\n",
      "2.45739913597 0.981183993951 457\n",
      "2.4527207077 0.981389565263 458\n",
      "2.43238240824 0.981591741458 459\n",
      "2.43084397505 0.98179366199 460\n",
      "2.42458168894 0.981994543495 461\n",
      "2.41962844609 0.982194605066 462\n",
      "2.40683709415 0.98239255698 463\n",
      "2.38104323493 0.982586288762 464\n",
      "2.38046594333 0.982779926614 465\n",
      "2.37174003781 0.982972147459 466\n",
      "2.36196591402 0.983162787255 467\n",
      "2.33930282921 0.983349786221 468\n",
      "2.33139344314 0.983535522804 469\n",
      "2.31471253152 0.983718611039 470\n",
      "2.31059522642 0.983901048515 471\n",
      "2.30227756206 0.984082174881 472\n",
      "2.29760332295 0.984262566524 473\n",
      "2.28530229896 0.984441031757 474\n",
      "2.27348909104 0.984617656711 475\n",
      "2.26087038824 0.984792326439 476\n",
      "2.25511961573 0.984966108713 477\n",
      "2.2456021064 0.985138427222 478\n",
      "2.22676897512 0.985307867492 479\n",
      "2.21933052678 0.985476177633 480\n",
      "2.21688898655 0.985644117655 481\n",
      "2.21202319444 0.98581132127 482\n",
      "2.2003712571 0.98597676802 483\n",
      "2.19246404359 0.986141027813 484\n",
      "2.18257867515 0.986303809718 485\n",
      "2.16910535643 0.986464588082 486\n",
      "2.15664104021 0.986623523996 487\n",
      "2.14415993427 0.986780625616 488\n",
      "2.13544424433 0.986936452643 489\n",
      "2.13246952962 0.987091845833 490\n",
      "2.11220088883 0.987244299106 491\n",
      "2.10556599723 0.987395796105 492\n",
      "2.09835709925 0.987546257508 493\n",
      "2.09068803691 0.987695621111 494\n",
      "2.07937888807 0.98784337318 495\n",
      "2.06563233213 0.98798917816 496\n",
      "2.06296330291 0.988134606591 497\n",
      "2.05899397745 0.988279475925 498\n",
      "2.04608271718 0.988422534102 499\n",
      "2.04017104272 0.988564766807 500\n",
      "2.0314527346 0.988705786497 501\n",
      "2.02164477984 0.988845447774 502\n",
      "2.01963761067 0.988984831867 503\n",
      "2.00520642112 0.989122231156 504\n",
      "1.99929086213 0.989258820957 505\n",
      "1.98642662568 0.989393658667 506\n",
      "1.97146923176 0.98952647342 507\n",
      "1.96279066409 0.989658121424 508\n",
      "1.95303710136 0.9897884643 509\n",
      "1.95101542049 0.989918537467 510\n",
      "1.94271199237 0.99004750582 511\n",
      "1.92621598029 0.990174293273 512\n",
      "1.92413429533 0.990300806832 513\n",
      "1.91254510515 0.990425800981 514\n",
      "1.9026470546 0.990549504706 515\n",
      "1.90030030277 0.990672903463 516\n",
      "1.8873734297 0.990794629081 517\n",
      "1.87140251275 0.990914303334 518\n",
      "1.86876051646 0.991033639921 519\n",
      "1.8589183318 0.9911517228 520\n",
      "1.84423228228 0.991267947264 521\n",
      "1.83945463769 0.991383570328 522\n",
      "1.8340549368 0.991498515569 523\n",
      "1.83151708012 0.99161314292 524\n",
      "1.81064148854 0.991725172123 525\n",
      "1.80489849118 0.991836491784 526\n",
      "1.80002519624 0.991947211122 527\n",
      "1.79135223132 0.992056866085 528\n",
      "1.78131661242 0.992165295858 529\n",
      "1.77299645942 0.992272715091 530\n",
      "1.76970348642 0.992379735677 531\n",
      "1.75608769976 0.992485115803 532\n",
      "1.74894777488 0.992589640759 533\n",
      "1.74196910809 0.992693333227 534\n",
      "1.72921284949 0.992795512597 535\n",
      "1.71771454477 0.992896337612 536\n",
      "1.70804392589 0.992996030547 537\n",
      "1.70427319146 0.993095283798 538\n",
      "1.69733069818 0.993193730063 539\n",
      "1.69327615249 0.993291706557 540\n",
      "1.68665765498 0.993388918628 541\n",
      "1.67872649742 0.993485218609 542\n",
      "1.66156385186 0.993579559589 543\n",
      "1.65880531584 0.993673587578 544\n",
      "1.64491927951 0.99376604792 545\n",
      "1.64223137896 0.993858206336 546\n",
      "1.63125042655 0.993949136419 547\n",
      "1.62378768892 0.994039236421 548\n",
      "1.61281138161 0.994128122444 549\n",
      "1.60778392958 0.994216455179 550\n",
      "1.59943705327 0.994303873129 551\n",
      "1.59444735828 0.994390746502 552\n",
      "1.59101737628 0.994477246511 553\n",
      "1.5848362535 0.99456307572 554\n",
      "1.56509826354 0.994646780359 555\n",
      "1.55976413721 0.994729915411 556\n",
      "1.55600161373 0.994812649864 557\n",
      "1.55216938964 0.994894977291 558\n",
      "1.54681641765 0.994976737851 559\n",
      "1.54312265183 0.995058108392 560\n",
      "1.52679546035 0.995137766141 561\n",
      "1.51665031882 0.9952163688 562\n",
      "1.50809877857 0.995294087564 563\n",
      "1.50253440762 0.995371233875 564\n",
      "1.49726989618 0.99544784053 565\n",
      "1.4790976529 0.995522598932 566\n",
      "1.46884478928 0.995596324499 567\n",
      "1.46492943109 0.995669657545 568\n",
      "1.45604953157 0.995742104245 569\n",
      "1.44555075933 0.995813509965 570\n",
      "1.43750552762 0.995884123078 571\n",
      "1.42326699781 0.99595334427 572\n",
      "1.41880806574 0.996022132417 573\n",
      "1.41141729639 0.996090205776 574\n",
      "1.40756667457 0.996157908207 575\n",
      "1.38893533103 0.996223830205 576\n",
      "1.38021939503 0.996288927443 577\n",
      "1.36234150646 0.996352349203 578\n",
      "1.34859516185 0.996414497539 579\n",
      "1.34756437485 0.996476550907 580\n",
      "1.33217738022 0.996537195267 581\n",
      "1.33015546857 0.996597655682 582\n",
      "1.31766687191 0.996656986122 583\n",
      "1.31322278905 0.99671591703 584\n",
      "1.30504458908 0.996774116229 585\n",
      "1.28850363488 0.996830849472 586\n",
      "1.27152784109 0.996886097663 587\n",
      "1.27024952018 0.996941234823 588\n",
      "1.26331676864 0.996995771771 589\n",
      "1.25989738713 0.997050013892 590\n",
      "1.25751340812 0.997104050933 591\n",
      "1.23467328182 0.997156142859 592\n",
      "1.22805069412 0.997207677458 593\n",
      "1.22501844059 0.997258957877 594\n",
      "1.22162709958 0.997309954759 595\n",
      "1.21680850725 0.99736055013 596\n",
      "1.20610391427 0.997410259215 597\n",
      "1.19805775498 0.997459307274 598\n",
      "1.18238879863 0.997507080759 599\n",
      "1.1695926105 0.9975538258 600\n",
      "1.16561458829 0.997600253402 601\n",
      "1.16025464523 0.997646255003 602\n",
      "1.14937556583 0.997691397984 603\n",
      "1.13542851565 0.997735452041 604\n",
      "1.12954424383 0.997779050667 605\n",
      "1.12112708255 0.997822001936 606\n",
      "1.11417245401 0.997864421983 607\n",
      "1.10657375647 0.99790626539 608\n",
      "1.10266763789 0.997947813911 609\n",
      "1.08449646894 0.997988004336 610\n",
      "1.08268326876 0.998028060482 611\n",
      "1.06984552384 0.998067172341 612\n",
      "1.06496693789 0.998105928307 613\n",
      "1.05449596225 0.998143925906 614\n",
      "1.04878627442 0.998181513134 615\n",
      "1.04479466575 0.998218814798 616\n",
      "1.0373623468 0.998255587647 617\n",
      "1.0257028415 0.998291538519 618\n",
      "1.01736690986 0.998326907417 619\n",
      "1.0119561625 0.998361901104 620\n",
      "1.00958932673 0.998396731292 621\n",
      "1.00382278921 0.998431164732 622\n",
      "1.0 0.998465336411 623\n",
      "1.0 0.998499508089 624\n",
      "0.999837435297 0.998533668658 625\n",
      "0.99513452517 0.998567508623 626\n",
      "0.991577465578 0.998601107101 627\n",
      "0.989530372942 0.998634566996 628\n",
      "0.988604857917 0.998667964329 629\n",
      "0.984043323482 0.998701054176 630\n",
      "0.981243505315 0.998733955994 631\n",
      "0.979714213359 0.998766755336 632\n",
      "0.97593574112 0.998799302171 633\n",
      "0.971589765785 0.99883155978 634\n",
      "0.969925159416 0.998863706951 635\n",
      "0.96874998372 0.998895776269 636\n",
      "0.959805722237 0.998927256143 637\n",
      "0.956550926389 0.998958522876 638\n",
      "0.948013358173 0.998989233966 639\n",
      "0.944133682114 0.999019694204 640\n",
      "0.931956382899 0.999049373766 641\n",
      "0.930641075863 0.999078969611 642\n",
      "0.926168898922 0.999108281695 643\n",
      "0.916719691037 0.999136998719 644\n",
      "0.914282502156 0.999165563252 645\n",
      "0.902765297418 0.999193412664 646\n",
      "0.893810550956 0.999220712325 647\n",
      "0.881842905488 0.999247285826 648\n",
      "0.859690596586 0.999272541017 649\n",
      "0.851444905982 0.999297314063 650\n",
      "0.844571275805 0.999321688743 651\n",
      "0.840942872664 0.999345854439 652\n",
      "0.82978808493 0.999369383289 653\n",
      "0.828550051886 0.999392841982 654\n",
      "0.825034059479 0.999416102001 655\n",
      "0.811764891414 0.999438619847 656\n",
      "0.801243480906 0.999460557761 657\n",
      "0.799379139718 0.999482393703 658\n",
      "0.788648970736 0.999503647366 659\n",
      "0.775171818239 0.999524180832 660\n",
      "0.764308095512 0.999544142794 661\n",
      "0.76162343231 0.999563964768 662\n",
      "0.748787573304 0.999583124242 663\n",
      "0.746428940861 0.999602163203 664\n",
      "0.725041192102 0.999620126733 665\n",
      "0.718019403003 0.999637744005 666\n",
      "0.711060763535 0.999655021459 667\n",
      "0.702883826787 0.999671903829 668\n",
      "0.695366567327 0.99968842702 669\n",
      "0.685212490146 0.999704471175 670\n",
      "0.668347435595 0.999719735264 671\n",
      "0.661929483364 0.999734707607 672\n",
      "0.658654116966 0.999749532144 673\n",
      "0.652757748881 0.999764092446 674\n",
      "0.64066118131 0.9997781181 675\n",
      "0.627659131474 0.999791580237 676\n",
      "0.623401052855 0.999804860338 677\n",
      "0.613538175532 0.999817723552 678\n",
      "0.611866734913 0.999830516776 679\n",
      "0.595977946538 0.999842654205 680\n",
      "0.589917572093 0.999854546043 681\n",
      "0.581283906398 0.999866092345 682\n",
      "0.564254146679 0.999876972017 683\n",
      "0.560313783388 0.999887700268 684\n",
      "0.537016517018 0.999897554927 685\n",
      "0.52844687444 0.999907097577 686\n",
      "0.52390429755 0.999916476873 687\n",
      "0.517265797667 0.99992561998 688\n",
      "0.490331304038 0.999933835699 689\n",
      "0.46901420592 0.999941352591 690\n",
      "0.456927615164 0.999948487051 691\n",
      "0.446028882496 0.999955285225 692\n",
      "0.436264644927 0.999961789013 693\n",
      "0.425141491837 0.999967965383 694\n",
      "0.41236878441 0.999973776209 695\n",
      "0.366117524112 0.99997835665 696\n",
      "0.356865032309 0.999982708504 697\n",
      "0.346760010146 0.999986817392 698\n",
      "0.316484578654 0.999990240113 699\n",
      "0.288046582503 0.999993075365 700\n",
      "0.267991857834 0.999995529563 701\n",
      "0.260959375844 0.999997856647 702\n",
      "0.250445757812 1.0 703\n",
      "2.28708257503e-14 1.0 704\n",
      "4.05796764859e-15 1.0 705\n",
      "4.05796764859e-15 1.0 706\n",
      "4.05796764859e-15 1.0 707\n",
      "4.05796764859e-15 1.0 708\n",
      "4.05796764859e-15 1.0 709\n",
      "4.05796764859e-15 1.0 710\n",
      "4.05796764859e-15 1.0 711\n",
      "7.95022108481e-16 1.0 712\n",
      "6.10618643467e-16 1.0 713\n",
      "4.09052482007e-16 1.0 714\n"
     ]
    }
   ],
   "source": [
    "# lest explore variablity of our latent features.\n",
    "# it seams 511 latent features can give us a reasonable prediction,\n",
    "# since they cover %99 percent of variablity.\n",
    "s_train_sqrd_sum = 0\n",
    "for s_val in s_train:\n",
    "    s_train_sqrd_sum += s_val**2\n",
    "    \n",
    "latent_percantage_sum = 0\n",
    "latent_counter = 0\n",
    "\n",
    "for s_val in s_train:\n",
    "    latent_percantage_sum += ((s_val**2)/s_train_sqrd_sum)\n",
    "    latent_counter += 1\n",
    "    print(s_val, latent_percantage_sum, latent_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Shapes of u, s, vt: (20, 511) (511, 511) (511, 574)\n",
      "Train SSE:  468.857931971\n",
      "Test SSE:  436.900726249\n"
     ]
    }
   ],
   "source": [
    "# I've follewed logic i've learned in lesson.\n",
    "# Find same users in test and train data as a list.\n",
    "# Find indexes of same users and articles.\n",
    "same_users_idx = [user_id-1 for user_id in list(set(test_idx).intersection(set(user_item_train.index.tolist())))]\n",
    "same_articles_idx = pd.DataFrame(user_item_train.columns).loc[pd.DataFrame(user_item_train.columns)['article_id'].isin(test_arts)].index.tolist()\n",
    "latent_feature_number = 511 # intuation from previous cell\n",
    "\n",
    "# Firts reshape u, s, and vt to apply dont product\n",
    "u_new = u_train[same_users_idx,:latent_feature_number]\n",
    "s_new = np.diag(s_train[:latent_feature_number])\n",
    "vt_new = vt_train[:latent_feature_number, same_articles_idx]\n",
    "print('New Shapes of u, s, vt:', u_new.shape, s_new.shape, vt_new.shape)\n",
    "\n",
    "# Make predictions\n",
    "preds = np.dot(np.dot(u_new, s_new),vt_new)\n",
    "\n",
    "# Calculate SSE of 20 users for both train and test data\n",
    "sse_train = np.sum(np.sum((user_item_train[user_item_train.index.isin(list(set(test_idx).intersection(set(user_item_train.index.tolist()))))][test_arts].values-preds)**2))\n",
    "sse_test = np.sum(np.sum((user_item_test[user_item_test.index.isin(list(set(test_idx).intersection(set(user_item_train.index.tolist()))))][test_arts].values-preds)**2))\n",
    "\n",
    "print('Train SSE: ', sse_train)\n",
    "print('Test SSE: ', sse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here.**\n",
    "\n",
    "**Answer BK:**\n",
    "\n",
    "*Question had 20 users and 574 articles are both train and test data. We've created u, s, vt and then choose 511 latent features to cover %99 percent variablity.*\n",
    "\n",
    "*We calculated SSE values for train and test data 468.86 , 436.90 respectively. On the other hand since we had a large SSE for this data set, unfortunately it can be stated that above svd recomendation will not an accurate model selection and falls behind User Based Collabrotive Filtering and Rank Based Collaborative Filtering respectively.*\n",
    "\n",
    "*Finally next step will be 2 phased test plan. First just like we did above we can calculate metrics for our 3 recommendation approach. That can be done with calculating SSE or RMSE of actual interaction vs recommended interactions on our user_item martix.*\n",
    "\n",
    "*After this evaluation it is possible that selecting best performing recommender to online test as A/B test explained in lessons would be a wise idea. This will give us oppurtunity to test our recommender design(our build choices, implementation and design process as a whole) in front of the most critical audience: users.*\n",
    "\n",
    "*We can create a pop up window for our users and place our recommendetion for that specific user when they logged on to the system. We can use Collabrotive Filtering or SVD according to best performing metrics discussed above. Also we should implement Rank Based method to new users to test it seperatly since our other two methods can't respond new users. After new pop up design we can show our reconmmendation half of the users visit our site and keep other half as control group. (note: Actually there were 2 tests. one for revisiting users, one for new users. But both will have half-half test and control groups to test our below hypotesis.)*\n",
    "\n",
    "*Then we can test the hypotesis that wheather new user recs (rank based) or revisiting user resc(CF or SVD) increases our intraction/click trough rate. If our recs will have large p values and we can't reject our hypotesis we can implement our recommenders as new features to our web site and ease article finding process for our users. Also we should ipmlement option 'can be dissable' to be restfectful for our users not to use recommenders chocie:)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
